{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will try to obtain the unique headers amongst all the csv files that we are going to merge. Then we will finally make a master comma seperated value file with list of headers that we obtain from this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the necessary libaries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import csv\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up parent directory and sub directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir = \"../Data/\"\n",
    "filelist = []\n",
    "dirs = []\n",
    "\n",
    "def makefilelist(parent_dir):\n",
    "    headers = []\n",
    "    csv_headers = []\n",
    "    subject_dirs = [os.path.join(parent_dir, dir) for dir in os.listdir(parent_dir) if os.path.isdir(os.path.join(parent_dir, dir))]\n",
    "    filelist = []\n",
    "    for dir in subject_dirs:\n",
    "        csv_files = [os.path.join(dir, csv) for csv in os.listdir(dir) if os.path.isfile(os.path.join(dir, csv)) and csv.endswith('.csv')]\n",
    "        for file in csv_files:\n",
    "            filelist.append(file)\n",
    "    \n",
    "    return filelist, subject_dirs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read headers from CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readCSV(fileList, subject_dirs):\n",
    "    master_csv_headers = []\n",
    "    for filename in fileList:\n",
    "        slash = filename.split(\"/\")\n",
    "        parts = slash[2]\n",
    "        subparts = parts.split(\"_\")\n",
    "        CIK = subparts[0]\n",
    "        report_type = subparts[1]\n",
    "        subsubpart = subparts[2].split('-')\n",
    "        report_year = subsubpart[1]\n",
    "        \n",
    "        with open(filename, 'r') as f:\n",
    "            d_reader = csv.DictReader(f)\n",
    "            headers = d_reader.fieldnames\n",
    "            for header in headers:\n",
    "                master_csv_headers.append(header)\n",
    "        \n",
    "        df = pd.read_csv(filename,engine='python')\n",
    "        df['CIK'] = CIK\n",
    "        df['Reporting Type'] = report_type\n",
    "        df['Report Year'] = report_year\n",
    "    \n",
    "        df.to_csv(filename, encoding='utf-8', index=False) \n",
    "            \n",
    "    return master_csv_headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'engine' is an invalid keyword argument for this function",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-95-729f0bb7f99e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfilelist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmakefilelist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcsv_headers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreadCSV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilelist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-94-49789de86319>\u001b[0m in \u001b[0;36mreadCSV\u001b[0;34m(fileList, subject_dirs)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mreport_year\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubsubpart\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'python'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0md_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDictReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mheaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfieldnames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'engine' is an invalid keyword argument for this function"
     ]
    }
   ],
   "source": [
    "filelist, dirs = makefilelist(parent_dir)\n",
    "csv_headers = readCSV(filelist, dirs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will only use the unqiue headers that we might require for our master CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniqueHeaders(csv_headers):\n",
    "    return list(set(csv_headers))\n",
    "\n",
    "def chomp(list1):\n",
    "    list1 = [x.replace('\\n', '') for x in list1]\n",
    "    return list1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking our unique header values and taking a look on the kind of values we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_headers = uniqueHeaders(csv_headers)\n",
    "print(len(final_headers))\n",
    "lol = chomp(final_headers)\n",
    "print(len(lol))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for different instances of similar headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "for header in lol:\n",
    "    if 'notional' in header.lower() or 'amount' in header.lower():\n",
    "        print(header)\n",
    "        counter+=1\n",
    "print (\"Counter\", counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will usse the above function as a way to guage how many similar ways are there to report a specific header and then merge all the occurances together to the master csv when we are conducting the joining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing the values present in the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeValues(filelist):\n",
    "    for filename in filelist:\n",
    "        with open(filename, 'r') as f:\n",
    "            df = pd.read_csv(filename, error_bad_lines=False)\n",
    "            headers = list(df)\n",
    "            for header in headers:\n",
    "                if '000' in header:\n",
    "                    df[header] = df[header].astype(str) + '000'\n",
    "            print (df)\n",
    "            print(\"Filename\", filename)        \n",
    "            df.to_csv(filename, index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "normalizeValues(filelist)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
